{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient calculation with PyTorch\n",
    "\n",
    "Although PyTorch already comes with a series of common loss functions, it is still important to be able to use PyTorch to calculate gradients at will for future model implementations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch uses **Autograd** to evaluate gradients values as specified values. See quadratic function example below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = 2.0\n",
      "f(x) = 11.0\n",
      "y type: <class 'torch.Tensor'>\n",
      "f'(x=2.0) = None\n",
      "f'(x=2.0) = 6.0\n"
     ]
    }
   ],
   "source": [
    "# Quadratic function example\n",
    "\n",
    "x = torch.tensor(\n",
    "    2, \n",
    "    requires_grad=True, #required_grad must be TRUE for gradient calculation\n",
    "    dtype=torch.float #doesn't work for integer types\n",
    ") \n",
    "\n",
    "y = 3 + 2*x + x**2 # f(x) = 3 + 2x + x^2 >> f'(x) = 2 + 2x\n",
    "\n",
    "print(f\"x = {x}\")\n",
    "print(f\"f(x) = {y}\")\n",
    "print(f\"y type: {type(y)}\")\n",
    "print(f\"f\\'(x={x}) = {x.grad}\")\n",
    "\n",
    "y.backward() #calculates gradient\n",
    "\n",
    "print(f\"f\\'(x={x}) = {x.grad}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = 2.0\n",
      "f(x) = 11.0\n",
      "f'(x=2.0) = None\n",
      "f'(x=2.0) = tensor([6.])\n"
     ]
    }
   ],
   "source": [
    "# Quadratic function example - non-scalar version\n",
    "\n",
    "x = torch.tensor(\n",
    "    [2], \n",
    "    requires_grad=True, #required_grad must be TRUE for gradient calculation\n",
    "    dtype=torch.float #doesn't work for integer types\n",
    ") \n",
    "\n",
    "y = 3 + 2*x[0] + x[0]**2 # f(x) = 3 + 2x + x^2 >> f'(x) = 2 + 2x\n",
    "\n",
    "print(f\"x = {x[0]}\")\n",
    "print(f\"f(x) = {y}\")\n",
    "print(f\"f\\'(x={x[0]}) = {x.grad}\")\n",
    "\n",
    "y.backward() #calculates gradient\n",
    "\n",
    "print(f\"f\\'(x={x[0]}) = {x.grad}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing gradients for multivariate functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x0=2.0\n",
      "x1=3.0\n",
      "f(2.0, 3.0)=37.0\n",
      "Gradient with respect to x0: None\n",
      "Gradient with respect to x1: None\n",
      "Gradient with respect to x0 (df/dx0(2,3)): 7.0\n",
      "Gradient with respect to x1 (df/dx1(2,3)): 29.0\n",
      "---vector version---\n",
      "x=tensor([2., 3.], dtype=torch.float16, requires_grad=True)\n",
      "f(x)=37.0\n",
      "f'(x)=None\n",
      "Gradient vector: f'(x)=tensor([ 7., 29.], dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "# Functions with multiple inputs:\n",
    "\n",
    "x0 = torch.tensor(\n",
    "    2,\n",
    "    requires_grad=True,\n",
    "    dtype=torch.float16\n",
    ")\n",
    "x1 = torch.tensor(\n",
    "    3,\n",
    "    requires_grad=True,\n",
    "    dtype=torch.float16\n",
    ")\n",
    "\n",
    "y = x0 ** 2 + x1 ** 3 + x0 * x1 # f(x) = x0^2 + x1^3 + x0 * x1\n",
    "\n",
    "print(f\"x0={x0}\")\n",
    "print(f\"x1={x1}\")\n",
    "print(f\"f({x0}, {x1})={y}\")\n",
    "print(f\"Gradient with respect to x0: {x0.grad}\")\n",
    "print(f\"Gradient with respect to x1: {x1.grad}\")\n",
    "\n",
    "y.backward()\n",
    "\n",
    "print(f\"Gradient with respect to x0 (df/dx0(2,3)): {x0.grad}\")\n",
    "print(f\"Gradient with respect to x1 (df/dx1(2,3)): {x1.grad}\")\n",
    "\n",
    "print(\"---vector version---\")\n",
    "\n",
    "\n",
    "x = torch.tensor(\n",
    "    [2,3],\n",
    "    requires_grad=True,\n",
    "    dtype=torch.float16\n",
    ")\n",
    "\n",
    "y = x[0] ** 2 + x[1] ** 3 + x[0] * x[1] # f(x) = x0^2 + x1^3 + x0 * x1\n",
    "\n",
    "print(f\"x={x}\")\n",
    "print(f\"f(x)={y}\")\n",
    "print(f\"f\\'(x)={x.grad}\")\n",
    "\n",
    "y.backward()\n",
    "\n",
    "print(f\"Gradient vector: f\\'(x)={x.grad}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = tensor([2., 3.], dtype=torch.float16, requires_grad=True)\n",
      "f(x) = tensor([16.0000, 27.6875], dtype=torch.float16, grad_fn=<StackBackward0>)\n",
      "iteration: 0\n",
      "0th row/gradient of 0th function: tensor([4., 4.])\n",
      "iteration: 1\n",
      "1th row/gradient of 1th function: tensor([ 0.5000, 27.0000])\n",
      "tensor([[ 4.0000,  4.0000],\n",
      "        [ 0.5000, 27.0000]])\n"
     ]
    }
   ],
   "source": [
    "# Vector function example\n",
    "\n",
    "x = torch.tensor([2,3], requires_grad=True, dtype=torch.float16)\n",
    "\n",
    "def vector_fn(x: torch.Tensor) -> torch.Tensor:\n",
    "    return torch.stack([\n",
    "        x[0] ** 2 + x[1] * 4,\n",
    "        x[1] ** 3 + torch.log(x[0])\n",
    "    ])\n",
    "\n",
    "y = vector_fn(x)\n",
    "\n",
    "print(f\"x = {x}\")\n",
    "print(f\"f(x) = {y}\")\n",
    "\n",
    "jacobian = torch.zeros(2,2)\n",
    "\n",
    "for i in range(2):\n",
    "    print(f\"iteration: {i}\")\n",
    "    # Zero out previous gradients\n",
    "    if x.grad is not None:\n",
    "        x.grad.zero_()\n",
    "    \n",
    "    # Compute gradient for each component\n",
    "    y[i].backward(\n",
    "        retain_graph=True #must set retain_graph=True for gradient computation more than once\n",
    "    ) \n",
    "    jacobian[i] = x.grad\n",
    "    print(f\"{i}th row/gradient of {i}th function: {jacobian[i]}\")\n",
    "\n",
    "print(jacobian)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss value: 3.0\n",
      "gradients: tensor([-2., -2., -2.], dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "# Sum square loss\n",
    "\n",
    "class MeanSquareLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, predictions, targets):\n",
    "        loss = torch.sum((targets - predictions) ** 2) #sum\n",
    "        return loss\n",
    "    \n",
    "predictions = torch.tensor([1,2,3], requires_grad=True, dtype=torch.float16)\n",
    "targets = torch.tensor([2,3,4], dtype=torch.float16)\n",
    "\n",
    "loss_function = MeanSquareLoss()\n",
    "loss = loss_function(predictions, targets)\n",
    "print(f\"loss value: {loss}\")\n",
    "\n",
    "loss.backward() #calculates gradients\n",
    "\n",
    "print(f\"gradients: {predictions.grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at more complicated functions below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss value: 1.0\n",
      "gradients: tensor([-0.6665, -0.6665, -0.6665], dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "# Mean square loss\n",
    "\n",
    "class MeanSquareLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, predictions, targets):\n",
    "        loss = torch.mean((targets - predictions) ** 2) #square\n",
    "        return loss\n",
    "    \n",
    "predictions = torch.tensor([1,2,3], requires_grad=True, dtype=torch.float16)\n",
    "targets = torch.tensor([2,3,4], dtype=torch.float16)\n",
    "\n",
    "loss_function = MeanSquareLoss()\n",
    "loss = loss_function(predictions, targets)\n",
    "print(f\"loss value: {loss}\")\n",
    "\n",
    "loss.backward() #calculates gradients\n",
    "\n",
    "print(f\"gradients: {predictions.grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss value: 4.6015625\n",
      "gradients evaluated to: tensor([-0.5498, -0.5498, -1.8496], dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "# More complex loss function\n",
    "\n",
    "class ComplexCustomLoss(nn.Module):\n",
    "    def __init__(self, alpha = 0.65, beta = 0.35):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "    \n",
    "    def forward(self, predictions, targets):\n",
    "        mse = torch.mean((targets - predictions) ** 2)\n",
    "        l1 = torch.mean(torch.abs(predictions - targets))\n",
    "\n",
    "        loss = self.alpha * mse + self.beta * l1\n",
    "        return loss\n",
    "    \n",
    "\n",
    "predictions = torch.tensor([1,2,3], requires_grad=True, dtype=torch.float16)\n",
    "targets = torch.tensor([2,3,7], dtype=torch.float16)\n",
    "\n",
    "loss_function = ComplexCustomLoss(alpha=0.65, beta=0.35)\n",
    "loss = loss_function(predictions, targets)\n",
    "\n",
    "print(f\"loss value: {loss}\")\n",
    "\n",
    "loss.backward() #calculate gradients\n",
    "\n",
    "print(f\"gradients evaluated to: {predictions.grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rec-sys",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
