{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning with PyTorch\n",
    "\n",
    "This notebook is used to understand how to implement SGD with PyTorch before experimenting with other algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.7.0.dev20250128+cpu'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test if pytorch is working\n",
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Wranggling\n",
    "\n",
    "PyTorch works with Tensor objects. Operations of Tensors behave like Numpy arrays and can be passed back and forth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1)\n",
      "tensor([1, 2])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor(1)\n",
    "print(a)\n",
    "\n",
    "b = torch.tensor([1, 2])\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 6,  8],\n",
      "        [10, 12]])\n",
      "tensor([[ 5, 12],\n",
      "        [21, 32]])\n",
      "tensor([[19, 22],\n",
      "        [43, 50]])\n"
     ]
    }
   ],
   "source": [
    "X = torch.tensor([[1,2],[3,4]])\n",
    "Y = torch.tensor([[5,6],[7,8]])\n",
    "\n",
    "print(X + Y)\n",
    "print(X * Y)\n",
    "print(X @ Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "1\n",
      "0\n",
      "---\n",
      "2\n",
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(X.dim()) #dimensions\n",
    "print(b.dim())\n",
    "print(a.dim())\n",
    "\n",
    "print(\"---\")\n",
    "\n",
    "print(X.ndim)\n",
    "print(b.ndim)\n",
    "print(a.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(18)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = torch.tensor([3, 4])\n",
    "v = torch.tensor([2, 3])\n",
    "\n",
    "torch.dot(u, v) # dot product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1D tensors expected, but got 2D and 2D tensors\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    torch.dot(X, Y) # doesn't work because dot products only works on vectors\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 3],\n",
      "        [2, 4]])\n"
     ]
    }
   ],
   "source": [
    "print(X.T) #transpose matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with Numpy\n",
    "\n",
    "PyTorch tensors can go hand to hand with Numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(X.numpy())\n",
    "type(X.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4, 5],\n",
      "        [6, 7]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(torch.from_numpy(np.array([[4,5],[6,7]])))\n",
    "type(torch.from_numpy(np.array([[4,5],[6,7]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.2763])\n",
      "tensor([[-1.0392, -0.7893],\n",
      "        [-0.0870,  0.0144],\n",
      "        [-0.6517,  0.2873]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.randn(1))\n",
    "print(torch.randn(3,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.5776, -1.3838], dtype=torch.float16, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(torch.randn(2, requires_grad=True, dtype=torch.float16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.2942,  1.7905, -0.6427, -0.6889],\n",
      "        [ 1.0933,  1.5447, -1.0101,  0.1803]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.normal(mean=0, std=1, size=(2,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is CUDA available: False\n",
      "is apple silicon available: False\n"
     ]
    }
   ],
   "source": [
    "# detect whether CUDA is available\n",
    "\n",
    "print(f\"is CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "# detect whether silicon GPU is available\n",
    "\n",
    "print(f\"is apple silicon available: {torch.backends.mps.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensors can be moved to GPUs using `TENSOR.to(device = \"cuda\")` or `TENSOR.to(device = \"mps\")`.\n",
    "\n",
    "Note that once a tensor is in a GPU, it cannot be exported to Numpy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OLS with PyTorch\n",
    "\n",
    "Below is code to create a simple OLS model with PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "100\n",
      "torch.float64\n",
      "torch.Size([100, 2])\n",
      "torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "# mock regression data\n",
    "\n",
    "weight = [0.77, -0.56]\n",
    "bias = np.random.normal(0,12)\n",
    "SEED = 9999\n",
    "\n",
    "X = np.random.rand(100, 2) * 10\n",
    "y = X @ weight + bias\n",
    "\n",
    "print(X.size)\n",
    "print(y.size)\n",
    "\n",
    "X = torch.from_numpy(X)\n",
    "print(X.dtype)\n",
    "y = torch.from_numpy(y)\n",
    "\n",
    "print(X.size())\n",
    "print(y.size())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All models in PyTorch must be created as a class (subclass of nn.Module) with a forward method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PyTorchOLS(nn.Module):\n",
    "    \"\"\"\n",
    "    Specifies NN architecture here\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        #initialize weights with a random vector\n",
    "        self.weights = nn.Parameter(\n",
    "            torch.randn(\n",
    "                2,\n",
    "                requires_grad=True, #PyTorch will track gradients of this param\n",
    "                dtype=torch.float64\n",
    "            )\n",
    "        )\n",
    "\n",
    "        #initialize bias with a random scalar\n",
    "        self.bias = nn.Parameter(\n",
    "            torch.randn(\n",
    "                1,\n",
    "                requires_grad=True, #PyTorch will track gradients of this param\n",
    "                dtype=torch.float64\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        This defines the forward computation of the model\n",
    "        \"\"\"\n",
    "        return torch.matmul(x, self.weights) + self.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class above defines the architecture of the model which is really a linear regression with 2 regressors. We can then create an instance of the model class and look at the parameters and its initial predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([0.3367, 0.1288], dtype=torch.float64, requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.2345], dtype=torch.float64, requires_grad=True)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42) #set seed\n",
    "\n",
    "OLS = PyTorchOLS() #initialize class\n",
    "\n",
    "list(OLS.parameters()) #checks current state of model (prior to training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weights', tensor([0.3367, 0.1288], dtype=torch.float64)),\n",
       "             ('bias', tensor([0.2345], dtype=torch.float64))])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OLS.state_dict() #checks current state of model (prior to training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([80, 2])\n",
      "torch.Size([10, 2])\n",
      "torch.Size([10, 2])\n",
      "torch.Size([80])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "# train validation test split\n",
    "\n",
    "X_train, X_validate, X_test = X[:80], X[80:90], X[90:]\n",
    "y_train, y_validate, y_test = y[:80], y[80:90], y[90:]\n",
    "\n",
    "print(X_train.size())\n",
    "print(X_validate.size())\n",
    "print(X_test.size())\n",
    "\n",
    "print(y_train.size())\n",
    "print(y_validate.size())\n",
    "print(y_test.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.9215, 1.7584, 4.1914, 3.1828, 2.1138, 2.0429, 2.3022, 0.4895, 3.4685,\n",
       "        2.8963], dtype=torch.float64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.inference_mode():\n",
    "    y_pred = OLS(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, \n",
      "            Training Loss: 24.4103,\n",
      "            Test Loss: 6.7783\n",
      "Epoch 11/100, \n",
      "            Training Loss: 4.3433,\n",
      "            Test Loss: 2.2605\n",
      "Epoch 21/100, \n",
      "            Training Loss: 4.0065,\n",
      "            Test Loss: 1.9760\n",
      "Epoch 31/100, \n",
      "            Training Loss: 3.7824,\n",
      "            Test Loss: 1.8518\n",
      "Epoch 41/100, \n",
      "            Training Loss: 3.5727,\n",
      "            Test Loss: 1.7472\n",
      "Epoch 51/100, \n",
      "            Training Loss: 3.3747,\n",
      "            Test Loss: 1.6501\n",
      "Epoch 61/100, \n",
      "            Training Loss: 3.1876,\n",
      "            Test Loss: 1.5586\n",
      "Epoch 71/100, \n",
      "            Training Loss: 3.0109,\n",
      "            Test Loss: 1.4722\n",
      "Epoch 81/100, \n",
      "            Training Loss: 2.8440,\n",
      "            Test Loss: 1.3906\n",
      "Epoch 91/100, \n",
      "            Training Loss: 2.6864,\n",
      "            Test Loss: 1.3135\n"
     ]
    }
   ],
   "source": [
    "#Training the model\n",
    "\n",
    "epochs = 100\n",
    "learning_rate = 0.01\n",
    "\n",
    "def MSE(\n",
    "    actual: torch.Tensor,\n",
    "    predicted: torch.Tensor\n",
    ") -> torch.Tensor:\n",
    "    return torch.mean((actual - predicted) ** 2)\n",
    "\n",
    "train_losses = []\n",
    "epoch_index = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    OLS.train() #puts model into train mode\n",
    "    y_pred = OLS(X_train)\n",
    "\n",
    "    loss = MSE(y_train, y_pred) #loss function here is MSE\n",
    "\n",
    "    loss.backward() #backwards pass\n",
    "\n",
    "    OLS.eval() #model is now in evaluation mode\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        # Update weights\n",
    "        OLS.weights -= learning_rate * OLS.weights.grad #updates weight param\n",
    "        OLS.bias -= learning_rate * OLS.bias.grad #updates bias param\n",
    "        \n",
    "        # Zero the gradients after updating weights\n",
    "        OLS.weights.grad.zero_()\n",
    "        OLS.bias.grad.zero_()\n",
    "\n",
    "        y_pred_validate = OLS(X_validate)\n",
    "        test_loss = MSE(y_pred_validate, y_validate.type(torch.float64))\n",
    "\n",
    "    epoch_index.append(epoch+1)\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"\"\"Epoch {epoch+1}/{epochs}, \n",
    "            Training Loss: {loss.item():.4f},\n",
    "            Test Loss: {test_loss.item():.4f}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([ 1.1114, -0.1739], dtype=torch.float64, requires_grad=True)\n",
      "tensor([-4.5440, -5.3779], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "y_pred = OLS(X_validate)\n",
    "torch.mean((y_validate - y_pred)).backward()\n",
    "print(OLS.weights)\n",
    "print(OLS.weights.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In PyTorch \"optimizers\" can be used to update weights with every training iteration. It is better for larger datasets calculations involving only a subset of the training dataset maybe used per iterations (ex. SGD algorithm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, \n",
      "            Training Loss: 2.5375,\n",
      "            Test Loss: 1.2024\n",
      "Epoch 11/100, \n",
      "            Training Loss: 2.3953,\n",
      "            Test Loss: 1.1721\n",
      "Epoch 21/100, \n",
      "            Training Loss: 2.2625,\n",
      "            Test Loss: 1.1064\n",
      "Epoch 31/100, \n",
      "            Training Loss: 2.1371,\n",
      "            Test Loss: 1.0450\n",
      "Epoch 41/100, \n",
      "            Training Loss: 2.0187,\n",
      "            Test Loss: 0.9870\n",
      "Epoch 51/100, \n",
      "            Training Loss: 1.9068,\n",
      "            Test Loss: 0.9323\n",
      "Epoch 61/100, \n",
      "            Training Loss: 1.8011,\n",
      "            Test Loss: 0.8806\n",
      "Epoch 71/100, \n",
      "            Training Loss: 1.7012,\n",
      "            Test Loss: 0.8318\n",
      "Epoch 81/100, \n",
      "            Training Loss: 1.6069,\n",
      "            Test Loss: 0.7857\n",
      "Epoch 91/100, \n",
      "            Training Loss: 1.5179,\n",
      "            Test Loss: 0.7422\n"
     ]
    }
   ],
   "source": [
    "#Training the model - with optimizers\n",
    "\n",
    "epochs = 100\n",
    "learning_rate = 0.01\n",
    "\n",
    "def MSE(\n",
    "    actual: torch.Tensor,\n",
    "    predicted: torch.Tensor\n",
    ") -> torch.Tensor:\n",
    "    return torch.mean((actual - predicted) ** 2)\n",
    "\n",
    "train_losses = []\n",
    "epoch_index = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    OLS.train() #puts model into train mode\n",
    "    y_pred = OLS(X_train)\n",
    "\n",
    "    loss = MSE(y_train, y_pred) #loss function here is MSE\n",
    "\n",
    "    loss.backward() #backwards pass\n",
    "\n",
    "    OLS.eval() #model is now in evaluation mode\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        # Update weights\n",
    "        OLS.weights -= learning_rate * OLS.weights.grad #updates weight param\n",
    "        OLS.bias -= learning_rate * OLS.bias.grad #updates bias param\n",
    "        \n",
    "        # Zero the gradients after updating weights\n",
    "        OLS.weights.grad.zero_()\n",
    "        OLS.bias.grad.zero_()\n",
    "\n",
    "        y_pred_validate = OLS(X_validate)\n",
    "        test_loss = MSE(y_pred_validate, y_validate.type(torch.float64))\n",
    "\n",
    "    epoch_index.append(epoch+1)\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"\"\"Epoch {epoch+1}/{epochs}, \n",
    "            Training Loss: {loss.item():.4f},\n",
    "            Test Loss: {test_loss.item():.4f}\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
