{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd9f52aa",
   "metadata": {},
   "source": [
    "# Long Short Term Memory (LSTM)\n",
    "\n",
    "Implementation of LSTM in time series data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a3cebeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d705e989",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Date</th><th>Close</th><th>High</th><th>Low</th><th>Open</th><th>Volume</th><th>Ticker</th></tr><tr><td>datetime[ns]</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>i64</td><td>str</td></tr></thead><tbody><tr><td>2023-01-03 00:00:00</td><td>43.092529</td><td>43.718036</td><td>42.75572</td><td>43.487079</td><td>3688279</td><td>&quot;SPLG&quot;</td></tr><tr><td>2023-01-04 00:00:00</td><td>43.42934</td><td>43.660294</td><td>42.996297</td><td>43.342732</td><td>4335811</td><td>&quot;SPLG&quot;</td></tr><tr><td>2023-01-05 00:00:00</td><td>42.928936</td><td>43.198383</td><td>42.861574</td><td>43.188762</td><td>4449438</td><td>&quot;SPLG&quot;</td></tr><tr><td>2023-01-06 00:00:00</td><td>43.900875</td><td>44.035599</td><td>42.928937</td><td>43.284993</td><td>2160602</td><td>&quot;SPLG&quot;</td></tr><tr><td>2023-01-09 00:00:00</td><td>43.881626</td><td>44.540814</td><td>43.862383</td><td>44.151077</td><td>4251681</td><td>&quot;SPLG&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 7)\n",
       "┌─────────────────────┬───────────┬───────────┬───────────┬───────────┬─────────┬────────┐\n",
       "│ Date                ┆ Close     ┆ High      ┆ Low       ┆ Open      ┆ Volume  ┆ Ticker │\n",
       "│ ---                 ┆ ---       ┆ ---       ┆ ---       ┆ ---       ┆ ---     ┆ ---    │\n",
       "│ datetime[ns]        ┆ f64       ┆ f64       ┆ f64       ┆ f64       ┆ i64     ┆ str    │\n",
       "╞═════════════════════╪═══════════╪═══════════╪═══════════╪═══════════╪═════════╪════════╡\n",
       "│ 2023-01-03 00:00:00 ┆ 43.092529 ┆ 43.718036 ┆ 42.75572  ┆ 43.487079 ┆ 3688279 ┆ SPLG   │\n",
       "│ 2023-01-04 00:00:00 ┆ 43.42934  ┆ 43.660294 ┆ 42.996297 ┆ 43.342732 ┆ 4335811 ┆ SPLG   │\n",
       "│ 2023-01-05 00:00:00 ┆ 42.928936 ┆ 43.198383 ┆ 42.861574 ┆ 43.188762 ┆ 4449438 ┆ SPLG   │\n",
       "│ 2023-01-06 00:00:00 ┆ 43.900875 ┆ 44.035599 ┆ 42.928937 ┆ 43.284993 ┆ 2160602 ┆ SPLG   │\n",
       "│ 2023-01-09 00:00:00 ┆ 43.881626 ┆ 44.540814 ┆ 43.862383 ┆ 44.151077 ┆ 4251681 ┆ SPLG   │\n",
       "└─────────────────────┴───────────┴───────────┴───────────┴───────────┴─────────┴────────┘"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get sample data\n",
    "\n",
    "import polars as pl\n",
    "import yfinance as yf\n",
    "import re\n",
    "\n",
    "prices = yf.download(\"SPLG\", start='2023-01-01', end='2024-01-01')\n",
    "\n",
    "df = (\n",
    "    pl\n",
    "    .from_pandas(\n",
    "        prices\n",
    "        .reset_index()\n",
    "    ).with_columns(\n",
    "        pl.lit(\"SPLG\").alias(\"Ticker\")\n",
    "    )\n",
    ")\n",
    "\n",
    "df.columns = [re.sub(r\"[^\\w\\s]\",\"\",header.split(\",\")[0]) for header in df.columns]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023b1318",
   "metadata": {},
   "source": [
    "## LSTM Model Class\n",
    "\n",
    "RNN with architecture consisting of 1 LSTM cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f11af4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleLSTM, self).__init__()\n",
    "\n",
    "        self.w_f = nn.Parameter(\n",
    "            torch.rand(1),\n",
    "            requires_grad=True\n",
    "        )\n",
    "        self.u_f = nn.Parameter(\n",
    "            torch.rand(1),\n",
    "            requires_grad=True\n",
    "        )\n",
    "        self.b_f = nn.Parameter(\n",
    "            torch.tensor(0.),\n",
    "            requires_grad=True\n",
    "        )\n",
    "\n",
    "        self.w_i = nn.Parameter(\n",
    "            torch.rand(1),\n",
    "            requires_grad=True\n",
    "        )\n",
    "        self.u_i = nn.Parameter(\n",
    "            torch.rand(1),\n",
    "            requires_grad=True\n",
    "        )\n",
    "        self.b_i = nn.Parameter(\n",
    "            torch.tensor(0.),\n",
    "            requires_grad=True\n",
    "        )\n",
    "\n",
    "        self.w_o = nn.Parameter(\n",
    "            torch.rand(1),\n",
    "            requires_grad=True\n",
    "        )\n",
    "        self.u_o = nn.Parameter(\n",
    "            torch.rand(1),\n",
    "            requires_grad=True\n",
    "        )\n",
    "        self.b_o = nn.Parameter(\n",
    "            torch.tensor(0.),\n",
    "            requires_grad=True\n",
    "        )\n",
    "\n",
    "        self.w_c = nn.Parameter(\n",
    "            torch.rand(1),\n",
    "            requires_grad=True\n",
    "        )\n",
    "        self.u_c = nn.Parameter(\n",
    "            torch.rand(1),\n",
    "            requires_grad=True\n",
    "        )\n",
    "        self.b_c = nn.Parameter(\n",
    "            torch.tensor(0.),\n",
    "            requires_grad=True\n",
    "        )\n",
    "\n",
    "    def cell(self, x, previous_short_term, previous_long_term):\n",
    "        \"\"\"\n",
    "            x: input\n",
    "            h_1: short term memory previously\n",
    "            c_1: long term memory previously\n",
    "        \"\"\"\n",
    "        lt_remember_pct = torch.sigmoid(self.w_f * x + self.u_f * previous_short_term + self.b_f) #forget gate\n",
    "\n",
    "        new_lt_remember_pct = torch.sigmoid(self.w_i * x + self.u_i * previous_short_term + self.b_i)\n",
    "        new_lt_memory = torch.relu(self.w_c * x + self.u_c * previous_short_term + self.b_c) #input gate\n",
    "\n",
    "        updated_lt_memory = lt_remember_pct * previous_long_term + new_lt_remember_pct * new_lt_memory\n",
    "\n",
    "        output_pct = torch.sigmoid(self.w_o * x + self.u_o * previous_short_term + self.b_o)\n",
    "        updated_st_memory = output_pct * torch.relu(updated_lt_memory)\n",
    "\n",
    "        return updated_st_memory, updated_lt_memory\n",
    "\n",
    "    def forward(self, input: torch.Tensor, h_1 = None, c_1 = None):\n",
    "        \"\"\"\n",
    "            x: input value\n",
    "            h_1: previous hidden state (if applicable) \n",
    "            c_1: previous memory (if applicable)\n",
    "        \"\"\"\n",
    "        if h_1 is None:\n",
    "            short_term_memory = torch.zeros(1, dtype=torch.float32)\n",
    "        else:\n",
    "            short_term_memory = h_1\n",
    "\n",
    "        if c_1 is None:\n",
    "            long_term_memory = torch.zeros(1, dtype=torch.float32)\n",
    "        else:\n",
    "            long_term_memory = h_1\n",
    "\n",
    "        for x in input.t():\n",
    "            short_term_memory, long_term_memory = self.cell(x, short_term_memory, long_term_memory)\n",
    "\n",
    "        return short_term_memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2ca167",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6c85280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppose we create a model with 4 lagged variables as entry\n",
    "\n",
    "data = df.select(pl.col(\"Close\").alias(\"y\"))\n",
    "data = data.with_columns(\n",
    "    pl.col(\"y\").shift(1).alias(\"x_1\"),\n",
    "    pl.col(\"y\").shift(2).alias(\"x_2\"),\n",
    "    pl.col(\"y\").shift(3).alias(\"x_3\"),\n",
    "    pl.col(\"y\").shift(4).alias(\"x_4\"),\n",
    ")\n",
    "data = data[4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0f9e394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([246, 4])\n",
      "torch.Size([246])\n"
     ]
    }
   ],
   "source": [
    "x_train = torch.FloatTensor(data.select(\"x_1\", \"x_2\", \"x_3\", \"x_4\").to_numpy())\n",
    "y_train = torch.FloatTensor(data[\"y\"].to_numpy())\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59fefb0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 100 [0/246 (0%)]\tLoss: 763.343384\n",
      "Train Epoch: 200 [0/246 (0%)]\tLoss: 2.198514\n",
      "Train Epoch: 300 [0/246 (0%)]\tLoss: 2.122788\n",
      "Train Epoch: 400 [0/246 (0%)]\tLoss: 2.028631\n",
      "Train Epoch: 500 [0/246 (0%)]\tLoss: 1.921827\n",
      "Train Epoch: 600 [0/246 (0%)]\tLoss: 1.807753\n",
      "Train Epoch: 700 [0/246 (0%)]\tLoss: 1.690243\n",
      "Train Epoch: 800 [0/246 (0%)]\tLoss: 1.570899\n",
      "Train Epoch: 900 [0/246 (0%)]\tLoss: 1.449723\n",
      "Train Epoch: 1000 [0/246 (0%)]\tLoss: 1.326119\n",
      "Train Epoch: 1100 [0/246 (0%)]\tLoss: 1.199883\n",
      "Train Epoch: 1200 [0/246 (0%)]\tLoss: 1.072503\n",
      "Train Epoch: 1300 [0/246 (0%)]\tLoss: 0.948139\n",
      "Train Epoch: 1400 [0/246 (0%)]\tLoss: 0.833684\n",
      "Train Epoch: 1500 [0/246 (0%)]\tLoss: 0.736847\n",
      "Train Epoch: 1600 [0/246 (0%)]\tLoss: 0.662800\n",
      "Train Epoch: 1700 [0/246 (0%)]\tLoss: 0.611747\n",
      "Train Epoch: 1800 [0/246 (0%)]\tLoss: 0.579544\n",
      "Train Epoch: 1900 [0/246 (0%)]\tLoss: 0.560409\n",
      "Train Epoch: 2000 [0/246 (0%)]\tLoss: 0.549301\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "# Setup hyperparamters\n",
    "batch_size = 40\n",
    "epochs = 2000\n",
    "learning_rate = 0.0001\n",
    "\n",
    "train_dataset = TensorDataset(x_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "\n",
    "model = SimpleLSTM()\n",
    "\n",
    "# Setup loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    total_loss = 0\n",
    "    model.train()\n",
    "    for batch_id, (data, target) in enumerate(train_loader): #for each batch, also get the index of batch\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data) #forward pass\n",
    "        loss = criterion(output, target)\n",
    "        # print(output)\n",
    "        # print(target)\n",
    "        loss.backward() #compute gradients\n",
    "        optimizer.step() #update weights\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "\n",
    "        if batch_id % 100 == 0 and epoch % 100 == 0: #update on training iterations\n",
    "            print(\"Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(\n",
    "                epoch, batch_id * len(data), len(train_loader.dataset),\n",
    "                100. * batch_id / len(train_loader), loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e38205",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rec-sys",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
