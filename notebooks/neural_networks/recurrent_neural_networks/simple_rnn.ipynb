{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "730af36e-cc3c-4b9c-9d2a-77202bd10485",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b861ba98-ba38-49b7-bcbc-5f2ebc395d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Date</th><th>Close</th><th>High</th><th>Low</th><th>Open</th><th>Volume</th><th>Ticker</th></tr><tr><td>datetime[ns]</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>i64</td><td>str</td></tr></thead><tbody><tr><td>2023-01-03 00:00:00</td><td>43.092079</td><td>43.71758</td><td>42.755273</td><td>43.486625</td><td>3688300</td><td>&quot;SPLG&quot;</td></tr><tr><td>2023-01-04 00:00:00</td><td>43.42889</td><td>43.659842</td><td>42.995852</td><td>43.342283</td><td>4335600</td><td>&quot;SPLG&quot;</td></tr><tr><td>2023-01-05 00:00:00</td><td>42.92849</td><td>43.197934</td><td>42.861129</td><td>43.188313</td><td>4449300</td><td>&quot;SPLG&quot;</td></tr><tr><td>2023-01-06 00:00:00</td><td>43.900417</td><td>44.03514</td><td>42.928489</td><td>43.284542</td><td>2160500</td><td>&quot;SPLG&quot;</td></tr><tr><td>2023-01-09 00:00:00</td><td>43.881172</td><td>44.545166</td><td>43.861929</td><td>44.15062</td><td>4251700</td><td>&quot;SPLG&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 7)\n",
       "┌─────────────────────┬───────────┬───────────┬───────────┬───────────┬─────────┬────────┐\n",
       "│ Date                ┆ Close     ┆ High      ┆ Low       ┆ Open      ┆ Volume  ┆ Ticker │\n",
       "│ ---                 ┆ ---       ┆ ---       ┆ ---       ┆ ---       ┆ ---     ┆ ---    │\n",
       "│ datetime[ns]        ┆ f64       ┆ f64       ┆ f64       ┆ f64       ┆ i64     ┆ str    │\n",
       "╞═════════════════════╪═══════════╪═══════════╪═══════════╪═══════════╪═════════╪════════╡\n",
       "│ 2023-01-03 00:00:00 ┆ 43.092079 ┆ 43.71758  ┆ 42.755273 ┆ 43.486625 ┆ 3688300 ┆ SPLG   │\n",
       "│ 2023-01-04 00:00:00 ┆ 43.42889  ┆ 43.659842 ┆ 42.995852 ┆ 43.342283 ┆ 4335600 ┆ SPLG   │\n",
       "│ 2023-01-05 00:00:00 ┆ 42.92849  ┆ 43.197934 ┆ 42.861129 ┆ 43.188313 ┆ 4449300 ┆ SPLG   │\n",
       "│ 2023-01-06 00:00:00 ┆ 43.900417 ┆ 44.03514  ┆ 42.928489 ┆ 43.284542 ┆ 2160500 ┆ SPLG   │\n",
       "│ 2023-01-09 00:00:00 ┆ 43.881172 ┆ 44.545166 ┆ 43.861929 ┆ 44.15062  ┆ 4251700 ┆ SPLG   │\n",
       "└─────────────────────┴───────────┴───────────┴───────────┴───────────┴─────────┴────────┘"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get sample data\n",
    "\n",
    "import polars as pl\n",
    "import yfinance as yf\n",
    "import re\n",
    "\n",
    "prices = yf.download(\"SPLG\", start='2023-01-01', end='2024-01-01')\n",
    "\n",
    "df = (\n",
    "    pl\n",
    "    .from_pandas(\n",
    "        prices\n",
    "        .reset_index()\n",
    "    ).with_columns(\n",
    "        pl.lit(\"SPLG\").alias(\"Ticker\")\n",
    "    )\n",
    ")\n",
    "\n",
    "df.columns = [re.sub(r\"[^\\w\\s]\",\"\",header.split(\",\")[0]) for header in df.columns]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d8190d-ee48-4889-907b-c4560c594ac7",
   "metadata": {},
   "source": [
    "# SPLG Simple RNN Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "309fa37a-a631-412b-ae88-9ae36cc86670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extremely basic 1-d 1-param Elman RNN cell - with another linear transformation after tanh activation\n",
    "\n",
    "class SPLGRNN(nn.Module):\n",
    "    def __init__(self, sequence_length = 1):\n",
    "        super(SPLGRNN, self).__init__()\n",
    "\n",
    "        self.w_x = nn.Parameter(\n",
    "            torch.randn(1,1, requires_grad=True, dtype=torch.float32)\n",
    "        )\n",
    "        self.w_h = nn.Parameter(\n",
    "            torch.randn(1,1, requires_grad=True, dtype=torch.float32)\n",
    "        )\n",
    "        self.b_h = nn.Parameter(\n",
    "            torch.randn(1, requires_grad=True, dtype=torch.float32)\n",
    "        )\n",
    "\n",
    "        self.w_y = nn.Parameter(\n",
    "            torch.randn(1, requires_grad=True, dtype=torch.float32)\n",
    "        )\n",
    "        self.b_y = nn.Parameter(\n",
    "            torch.randn(1, requires_grad=True, dtype=torch.float32)\n",
    "        )\n",
    "\n",
    "        self.seq_len = sequence_length\n",
    "\n",
    "    def forward(self, x, h = None):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "\n",
    "        x = input data\n",
    "        h = hidden state value from previous iteration (default to 0 if not applicable)\n",
    "        \"\"\"\n",
    "\n",
    "        if len(x.shape) <= 1:\n",
    "            x = x.unsqueeze(1)\n",
    "            output = []\n",
    "\n",
    "        if h is None:\n",
    "            h = torch.zeros(1, dtype=torch.float32)\n",
    "\n",
    "        h_1 = h\n",
    "\n",
    "        x = x.to(dtype=torch.float32) #ensure type is aligned\n",
    "        seq = 0\n",
    "        \n",
    "        for entry in x: #loop is used to ensure hidden states carry through iterations\n",
    "            h_1 = torch.relu(\n",
    "                entry @ self.w_x.t() + h_1 @ self.w_h.t() + self.b_h\n",
    "            )\n",
    "            y = h_1 @ self.w_y.t() + self.b_y\n",
    "            output.append(y)\n",
    "            if seq >= self.seq_len:\n",
    "                seq = 0\n",
    "                h_1 = h\n",
    "            else:\n",
    "                seq += 1\n",
    "\n",
    "        output = torch.stack(output)\n",
    "        if len(x.shape) <= 1:\n",
    "            output = output.squeeze(1)\n",
    "\n",
    "        return output, h_1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2699d89",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "### Prep dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d4bd42c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([249])\n",
      "torch.Size([249])\n"
     ]
    }
   ],
   "source": [
    "x_train = torch.FloatTensor(df[\"Close\"].to_list()[:-1])\n",
    "y_train = torch.FloatTensor(df[\"Close\"].to_list()[1:])\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7919bb",
   "metadata": {},
   "source": [
    "### Setup Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e802c519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 100 [0/249 (0%)]\tLoss: 16.223093\n",
      "Train Epoch: 200 [0/249 (0%)]\tLoss: 16.495329\n",
      "Train Epoch: 300 [0/249 (0%)]\tLoss: 16.286247\n",
      "Train Epoch: 400 [0/249 (0%)]\tLoss: 15.068651\n",
      "Train Epoch: 500 [0/249 (0%)]\tLoss: 16.254644\n",
      "Train Epoch: 600 [0/249 (0%)]\tLoss: 13.322811\n",
      "Train Epoch: 700 [0/249 (0%)]\tLoss: 15.926310\n",
      "Train Epoch: 800 [0/249 (0%)]\tLoss: 10.887211\n",
      "Train Epoch: 900 [0/249 (0%)]\tLoss: 11.582383\n",
      "Train Epoch: 1000 [0/249 (0%)]\tLoss: 8.767213\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "# Setup hyperparamters\n",
    "sequence_length = 5\n",
    "batch_size = 50\n",
    "epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "train_dataset = TensorDataset(x_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Setup model\n",
    "model = SPLGRNN(sequence_length=sequence_length)\n",
    "\n",
    "# Setup loss function and optimizer\n",
    "criterion = nn.MSELoss() #there is no RMSE\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    total_loss = 0\n",
    "    model.train()\n",
    "    for batch_id, (data, target) in enumerate(train_loader): #for each batch, also get the index of batch\n",
    "        optimizer.zero_grad()\n",
    "        output, _ = model(data) #forward pass\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward() #compute gradients\n",
    "        optimizer.step() #update weights\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "\n",
    "        if batch_id % 100 == 0 and epoch % 100 == 0: #update on training iterations\n",
    "            print(\"Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(\n",
    "                epoch, batch_id * len(data), len(train_loader.dataset),\n",
    "                100. * batch_id / len(train_loader), loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "799f3252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[45.9542],\n",
       "         [46.2629],\n",
       "         [46.0607],\n",
       "         [46.4551],\n",
       "         [46.4490],\n",
       "         [46.5781],\n",
       "         [46.6312],\n",
       "         [46.8724],\n",
       "         [46.9479],\n",
       "         [46.9051],\n",
       "         [46.6271],\n",
       "         [46.4850],\n",
       "         [46.6508],\n",
       "         [47.0369],\n",
       "         [47.0269],\n",
       "         [47.0307],\n",
       "         [47.2342],\n",
       "         [47.2821],\n",
       "         [46.8660],\n",
       "         [47.3118],\n",
       "         [47.5133],\n",
       "         [47.7803],\n",
       "         [47.5898],\n",
       "         [47.4754],\n",
       "         [47.5430],\n",
       "         [47.5104],\n",
       "         [47.3459],\n",
       "         [47.3804],\n",
       "         [47.5997],\n",
       "         [47.6046],\n",
       "         [47.4843],\n",
       "         [47.3928],\n",
       "         [47.3454],\n",
       "         [46.9695],\n",
       "         [46.9405],\n",
       "         [47.0421],\n",
       "         [46.6743],\n",
       "         [46.9078],\n",
       "         [46.8424],\n",
       "         [46.7716],\n",
       "         [46.9083],\n",
       "         [47.2063],\n",
       "         [47.0343],\n",
       "         [46.9329],\n",
       "         [46.9638],\n",
       "         [46.6195],\n",
       "         [46.3676],\n",
       "         [46.3312],\n",
       "         [46.4551],\n",
       "         [46.5195],\n",
       "         [46.8289],\n",
       "         [46.6229],\n",
       "         [46.7921],\n",
       "         [47.0246],\n",
       "         [46.5506],\n",
       "         [46.7721],\n",
       "         [46.8831],\n",
       "         [46.9229],\n",
       "         [46.8877],\n",
       "         [47.1469],\n",
       "         [47.0810],\n",
       "         [47.5249],\n",
       "         [47.5976],\n",
       "         [47.4918],\n",
       "         [47.4324],\n",
       "         [47.5147],\n",
       "         [47.3561],\n",
       "         [47.5300],\n",
       "         [47.4640],\n",
       "         [47.7034],\n",
       "         [47.6691],\n",
       "         [47.7318],\n",
       "         [47.5643],\n",
       "         [47.7470],\n",
       "         [47.6378],\n",
       "         [47.6531],\n",
       "         [47.6728],\n",
       "         [47.3703],\n",
       "         [47.1164],\n",
       "         [47.6508],\n",
       "         [47.8221],\n",
       "         [47.8111],\n",
       "         [47.5910],\n",
       "         [47.4525],\n",
       "         [47.1478],\n",
       "         [47.6666],\n",
       "         [47.6807],\n",
       "         [47.5983],\n",
       "         [47.6804],\n",
       "         [47.6493],\n",
       "         [47.4386],\n",
       "         [47.6915],\n",
       "         [47.5629],\n",
       "         [47.7942],\n",
       "         [47.9720],\n",
       "         [47.9571],\n",
       "         [47.7804],\n",
       "         [47.7441],\n",
       "         [47.6064],\n",
       "         [47.7669],\n",
       "         [48.0230],\n",
       "         [48.0162],\n",
       "         [47.7372],\n",
       "         [48.0896],\n",
       "         [48.3859],\n",
       "         [48.3479],\n",
       "         [48.3831],\n",
       "         [48.3243],\n",
       "         [48.2479],\n",
       "         [48.4691],\n",
       "         [48.6508],\n",
       "         [48.7852],\n",
       "         [48.8093],\n",
       "         [49.0570],\n",
       "         [48.8137],\n",
       "         [48.8927],\n",
       "         [48.7866],\n",
       "         [48.8611],\n",
       "         [48.7115],\n",
       "         [48.6280],\n",
       "         [48.6532],\n",
       "         [48.8526],\n",
       "         [48.9284],\n",
       "         [49.1694],\n",
       "         [49.2099],\n",
       "         [49.1746],\n",
       "         [48.8228],\n",
       "         [48.9520],\n",
       "         [49.0077],\n",
       "         [49.1421],\n",
       "         [49.3005],\n",
       "         [49.4708],\n",
       "         [49.2606],\n",
       "         [49.5298],\n",
       "         [49.6769],\n",
       "         [49.7249],\n",
       "         [49.5949],\n",
       "         [49.5944],\n",
       "         [49.4973],\n",
       "         [49.7438],\n",
       "         [49.7410],\n",
       "         [49.6108],\n",
       "         [49.8114],\n",
       "         [49.8438],\n",
       "         [49.6077],\n",
       "         [49.5037],\n",
       "         [49.4283],\n",
       "         [49.3451],\n",
       "         [49.5262],\n",
       "         [49.4363],\n",
       "         [49.1068],\n",
       "         [49.2924],\n",
       "         [49.2775],\n",
       "         [49.4076],\n",
       "         [49.1675],\n",
       "         [49.0008],\n",
       "         [48.6689],\n",
       "         [48.8645],\n",
       "         [48.9995],\n",
       "         [48.9409],\n",
       "         [49.1694],\n",
       "         [48.8864],\n",
       "         [48.8425],\n",
       "         [49.1572],\n",
       "         [49.4583],\n",
       "         [49.5464],\n",
       "         [49.5113],\n",
       "         [49.5546],\n",
       "         [49.2764],\n",
       "         [49.3208],\n",
       "         [49.2539],\n",
       "         [49.2852],\n",
       "         [49.4273],\n",
       "         [49.3017],\n",
       "         [49.1462],\n",
       "         [49.5135],\n",
       "         [49.2469],\n",
       "         [49.2687],\n",
       "         [49.2292],\n",
       "         [49.0390],\n",
       "         [48.5202],\n",
       "         [48.6478],\n",
       "         [48.7355],\n",
       "         [48.4468],\n",
       "         [48.4495],\n",
       "         [48.5683],\n",
       "         [48.3301],\n",
       "         [48.5044],\n",
       "         [48.2399],\n",
       "         [48.3892],\n",
       "         [48.3780],\n",
       "         [48.6036],\n",
       "         [48.5518],\n",
       "         [48.8459],\n",
       "         [48.9264],\n",
       "         [48.8119],\n",
       "         [48.7006],\n",
       "         [48.9099],\n",
       "         [48.7340],\n",
       "         [48.6408],\n",
       "         [48.4741],\n",
       "         [48.2279],\n",
       "         [48.1951],\n",
       "         [48.3415],\n",
       "         [47.8708],\n",
       "         [47.8174],\n",
       "         [47.7301],\n",
       "         [47.9554],\n",
       "         [48.0870],\n",
       "         [48.2975],\n",
       "         [48.4885],\n",
       "         [48.8535],\n",
       "         [48.8908],\n",
       "         [48.9504],\n",
       "         [48.9744],\n",
       "         [48.8161],\n",
       "         [48.9518],\n",
       "         [49.1130],\n",
       "         [49.5136],\n",
       "         [49.5589],\n",
       "         [49.5868],\n",
       "         [49.6067],\n",
       "         [49.5773],\n",
       "         [49.7294],\n",
       "         [49.8053],\n",
       "         [49.8096],\n",
       "         [49.7859],\n",
       "         [49.8016],\n",
       "         [49.5971],\n",
       "         [49.8721],\n",
       "         [49.9960],\n",
       "         [49.8897],\n",
       "         [49.8813],\n",
       "         [49.7902],\n",
       "         [49.7634],\n",
       "         [50.0430],\n",
       "         [50.1353],\n",
       "         [50.2308],\n",
       "         [50.5282],\n",
       "         [50.6087],\n",
       "         [50.3811],\n",
       "         [50.6960],\n",
       "         [50.8286],\n",
       "         [50.4953],\n",
       "         [50.7283],\n",
       "         [50.7612],\n",
       "         [50.6637],\n",
       "         [50.9040],\n",
       "         [50.9170]], grad_fn=<StackBackward0>),\n",
       " tensor([18.1081], grad_fn=<ReluBackward0>))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = model(x_train)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "21e3bd1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'w_x': Parameter containing:\n",
       " tensor([[0.1684]], requires_grad=True),\n",
       " 'w_h': Parameter containing:\n",
       " tensor([[0.0044]], requires_grad=True),\n",
       " 'b_h': Parameter containing:\n",
       " tensor([8.7976], requires_grad=True),\n",
       " 'w_y': Parameter containing:\n",
       " tensor([2.4152], requires_grad=True),\n",
       " 'b_y': Parameter containing:\n",
       " tensor([7.1824], requires_grad=True)}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7504a320",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rec-sys",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
